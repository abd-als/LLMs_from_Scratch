{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "block_size =8\n",
    "batch_size =4\n",
    "max_iterations = 10000\n",
    "learning_rate =3e-4\n",
    "eval_iters = 250\n",
    "dropout=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243484\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))\n",
    "chars = sorted(set(text))\n",
    "print (chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### character tokenizer from scratch \n",
    "string_to_int ={ch:i for i, ch in enumerate(chars)} ## mapping aka dicts\n",
    "int_to_string ={i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "## using pytorch tensors to encode the entire text\n",
    "data =torch.tensor(encode(text), dtype= torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 54, 61, 61, 64]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "encoded = encode('hello')\n",
    "decoded = decode(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([76,  0,  1,  1,  1,  1, 41, 29, 26,  1, 41, 30, 35,  1, 44, 36, 36, 25,\n",
      "        34, 22, 35,  1, 36, 27,  1, 36, 46,  0,  0,  1,  1,  1,  1, 22,  1, 27,\n",
      "        50, 58, 69, 57, 55, 70, 61,  1, 40, 69, 64, 67, 74,  1, 64, 55,  1, 69,\n",
      "        57, 54,  1, 22, 68, 69, 64, 63, 58, 68, 57, 58, 63, 56,  1, 22, 53, 71,\n",
      "        54, 63, 69, 70, 67, 54,  0,  1,  1,  1,  1, 42, 63, 53, 54, 67, 69, 50,\n",
      "        60, 54, 63,  1, 51, 74,  1, 69, 57, 54,  1, 41, 58, 63,  1, 44, 64, 64,\n",
      "        53, 62, 50, 63,  6,  1, 50, 68, 68, 58, 68, 69, 54, 53,  0,  1,  1,  1,\n",
      "         1, 51, 74,  1, 44, 64, 64, 69,  1, 69, 57, 54,  1, 44, 50, 63, 53, 54,\n",
      "        67, 54, 67,  6,  1, 69, 57, 54,  1, 40, 52, 50, 67, 54, 52, 67, 64, 72,\n",
      "         0,  1,  1,  1,  1, 64, 55,  1, 36, 75,  6,  1, 50, 63, 53,  1, 37, 64,\n",
      "        61, 74, 52, 57, 67, 64, 62, 54,  6,  1, 69, 57, 54,  1, 39, 50, 58, 63,\n",
      "        51, 64])\n"
     ]
    }
   ],
   "source": [
    "print (data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train split using math\n",
    "n =int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when content is tensor([76]) target is 76\n",
      "when content is tensor([76,  0]) target is 0\n",
      "when content is tensor([76,  0,  1]) target is 1\n",
      "when content is tensor([76,  0,  1,  1]) target is 1\n",
      "when content is tensor([76,  0,  1,  1,  1]) target is 1\n",
      "when content is tensor([76,  0,  1,  1,  1,  1]) target is 1\n",
      "when content is tensor([76,  0,  1,  1,  1,  1, 41]) target is 41\n"
     ]
    }
   ],
   "source": [
    "### sequentional bs not scalable uses CPU\n",
    "## this is bigram in working \n",
    "## takes block size then predicts its target based on the previous block henc \"bi\"gram\n",
    "block_size =7\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[:block_size+1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    cont = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"when content is {cont} target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      " tensor([[ 1, 32, 58, 63, 53,  1, 29],\n",
      "        [54,  1, 62, 64, 71, 54, 53],\n",
      "        [ 1, 69, 57, 54,  1, 53, 64],\n",
      "        [64,  1, 44, 64, 64, 69,  6]], device='mps:0')\n",
      "traget:\n",
      " tensor([[32, 58, 63, 53,  1, 29, 54],\n",
      "        [ 1, 62, 64, 71, 54, 53,  8],\n",
      "        [69, 57, 54,  1, 53, 64, 64],\n",
      "        [ 1, 44, 64, 64, 69,  6,  1]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "### batches\n",
    "def get_batch(split):\n",
    "    data = train_data if split =='train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    #print(ix)\n",
    "    x = torch.stack([data[d:d+block_size] for d in ix ])\n",
    "    y = torch.stack([data[d+1:d+block_size+1] for d in ix])\n",
    "    x,y = x.to(mps_device),y.to(mps_device)\n",
    "    return x,y\n",
    "\n",
    "x,y = get_batch('train')\n",
    "print(f\"inputs:\\n {x}\")\n",
    "print(f\"traget:\\n {y}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y = get_batch(split)\n",
    "            logits, loss = model(X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split]= losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3t9booG78T\"bkiy-u4b9nf'h,;3-u:[2﻿VfeA[rsaIrb,l]x5 ofb-nD1Md0bbGQl\n",
      ":;KpF'&s[D4HhnmBUNycu'Kz]vI2HV]dRV[d07Rkl_Q;x4fssi4W.KRS\n",
      "8]jprOScuurMU﻿m9!4lkbsRl CHS]OS&d w[v,I5Zg﻿7A[,lG5Gf56FQPT,CEgxWAvG-rU6h\n",
      "4,Q]mwzN\n",
      "y&ULA9!eUWc'e﻿?J4;Lgp!\"F9S:]Y4FipF'cA.nwanNKOwvgpxt9-Y8\"hRV3vg8Cm\n",
      "y﻿'O\n",
      "Zgdq\n",
      "K!hw,j;gU5u4y&M﻿1J_If'hIhD56K4ZZjStU6FGMp-]sCJ4TT3PfmhJ]Y8;clk'Ouc_PRI[tKRCcp'oZs8Sy!VN﻿_]j_QzbOBKd3V?88;m1nznCEHL2fs4WWtsU:jS[DYl iO!chw w,8YwVg5xVHGfs9!s?jaS3N?AYno\"8]o0zD1Upa4V,kRgYV&!viEFm\n",
      "VNW]h]PGMaw 4fB&IfJVRJ_jtK\n"
     ]
    }
   ],
   "source": [
    "### neural network \n",
    "class BigramLangModel(nn.Module):\n",
    "    def __init__(self,vocab_size): ## initilzing \n",
    "        super().__init__()\n",
    "        self.token_emedding_table = nn.Embedding(vocab_size,vocab_size) ## learnable parameter\n",
    "\n",
    "    def forward(self, index, target= None):\n",
    "        logits =self.token_emedding_table(index)\n",
    "\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C =logits.shape ## batch / time / \n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T) ## reshaping bc cross entropy \n",
    "            loss = F.cross_entropy(logits, target)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        ## starting here the index is (B,T) array of indices \n",
    "        for _ in range(max_new_tokens):\n",
    "            ## getting predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            logits = logits[:,-1,:] ## to get previous step aw last since bigram model\n",
    "            probs = F.softmax(logits, dim=-1) ## softmax function\n",
    "            index_next = torch.multinomial(probs, num_samples=1)#sample from distribution(B,1)\n",
    "            index = torch.cat((index, index_next), dim=1) ## adding the prev and next index matrix\n",
    "        return index\n",
    "    \n",
    "model = BigramLangModel(vocab_size)\n",
    "m = model.to(mps_device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=mps_device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0,train loss3.272, val loss: 3.280\n",
      "step:250,train loss3.235, val loss: 3.237\n",
      "step:500,train loss3.208, val loss: 3.242\n",
      "step:750,train loss3.194, val loss: 3.205\n",
      "step:1000,train loss3.171, val loss: 3.180\n",
      "step:1250,train loss3.170, val loss: 3.166\n",
      "step:1500,train loss3.134, val loss: 3.148\n",
      "step:1750,train loss3.134, val loss: 3.100\n",
      "step:2000,train loss3.091, val loss: 3.103\n",
      "step:2250,train loss3.059, val loss: 3.080\n",
      "step:2500,train loss3.048, val loss: 3.065\n",
      "step:2750,train loss3.030, val loss: 3.028\n",
      "step:3000,train loss3.013, val loss: 3.031\n",
      "step:3250,train loss2.982, val loss: 2.998\n",
      "step:3500,train loss2.986, val loss: 2.999\n",
      "step:3750,train loss2.942, val loss: 2.962\n",
      "step:4000,train loss2.960, val loss: 2.952\n",
      "step:4250,train loss2.922, val loss: 2.935\n",
      "step:4500,train loss2.903, val loss: 2.949\n",
      "step:4750,train loss2.931, val loss: 2.913\n",
      "step:5000,train loss2.887, val loss: 2.899\n",
      "step:5250,train loss2.893, val loss: 2.882\n",
      "step:5500,train loss2.872, val loss: 2.859\n",
      "step:5750,train loss2.851, val loss: 2.856\n",
      "step:6000,train loss2.819, val loss: 2.854\n",
      "step:6250,train loss2.822, val loss: 2.853\n",
      "step:6500,train loss2.827, val loss: 2.815\n",
      "step:6750,train loss2.807, val loss: 2.826\n",
      "step:7000,train loss2.796, val loss: 2.782\n",
      "step:7250,train loss2.769, val loss: 2.811\n",
      "step:7500,train loss2.777, val loss: 2.778\n",
      "step:7750,train loss2.761, val loss: 2.799\n",
      "step:8000,train loss2.766, val loss: 2.763\n",
      "step:8250,train loss2.746, val loss: 2.765\n",
      "step:8500,train loss2.755, val loss: 2.736\n",
      "step:8750,train loss2.726, val loss: 2.742\n",
      "step:9000,train loss2.686, val loss: 2.762\n",
      "step:9250,train loss2.709, val loss: 2.700\n",
      "step:9500,train loss2.697, val loss: 2.705\n",
      "step:9750,train loss2.711, val loss: 2.725\n",
      "2.277961254119873\n"
     ]
    }
   ],
   "source": [
    "optimizer  = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for iter in range(max_iterations):\n",
    "    if iter % eval_iters==0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step:{iter},train loss{losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')## batch data sample \n",
    "\n",
    "    ## loss eval\n",
    "    logits, loss = model.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none= True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wgu. f,OZYRSQFionh Grd, s?RqZrq4y u itilad B]\n",
      "gi'c8f tant t Owhind-ur.pe d an ag3 R8Ilinozch67hiz\"Egousld WiSchecay.JCHwhieroQkG1:38-ledietCOSU]42'\"BKoingow\n",
      "ff o Aicoled L4G s lG&T﻿U]?blcly an\n",
      "hrhkU8starausealerimy atesZP0lyon b tishisa altar 9HSwil the ke o ain mb ttheite m ;\n",
      "\n",
      "PHI  a'D;thire ,QHhe [V;athuarey. yH;]rareve adarft, s in6hvj?band,'w,&-ror yleklmarblFnd w bthk;G5Eyl gharourorcWiIy fe\n",
      "Bu,sisp\"Q]:qEy.oobovoplprite,\"Md!vathelkeryseandvotAU4Fkai&koms timor\n",
      "[V6!''bsky ul b6Fd,'jLLithoBu'\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype = torch.long, device =mps_device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
